------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (12580 examples) in 25.294s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 12580
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 59.762s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (11360 examples) in 26.839s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 23940
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 57.647s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (11260 examples) in 24.792s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 35200
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 50.491s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (11300 examples) in 31.932s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 46500
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 55.284s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (8280 examples) in 27.855s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 54780
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 53.831s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (9610 examples) in 24.344s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 64390
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 41.931s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (10500 examples) in 25.280s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 74890
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 54.515s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (10360 examples) in 27.188s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win12, lose8, draw0
[EVALUATION RESULT]:(first)  win5, lose5, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 8 in 80.224s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (2620 examples) in 14.549s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win10, lose9, draw1
[EVALUATION RESULT]:(first)  win6, lose3, draw1
[EVALUATION RESULT]:(second) win4, lose6, draw0
------ Finished Self-Play Iteration 9 in 48.488s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (1120 examples) in 2.815s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win13, lose7, draw0
[EVALUATION RESULT]:(first)  win6, lose4, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 10 in 34.714s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (470 examples) in 0.530s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win15, lose5, draw0
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 11 in 32.111s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (2520 examples) in 15.176s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win10, lose8, draw2
[EVALUATION RESULT]:(first)  win6, lose4, draw0
[EVALUATION RESULT]:(second) win4, lose4, draw2
------ Finished Self-Play Iteration 12 in 47.966s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (1100 examples) in 3.417s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win12, lose8, draw0
[EVALUATION RESULT]:(first)  win6, lose4, draw0
[EVALUATION RESULT]:(second) win6, lose4, draw0
------ Finished Self-Play Iteration 13 in 34.243s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (1680 examples) in 8.737s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 14 in 39.916s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (1870 examples) in 9.623s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose3, draw1
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win9, lose0, draw1
------ Finished Self-Play Iteration 15 in 41.182s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (660 examples) in 1.832s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win15, lose5, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 16 in 35.796s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (610 examples) in 1.053s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win13, lose7, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win4, lose6, draw0
------ Finished Self-Play Iteration 17 in 33.913s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (1510 examples) in 9.281s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win9, lose9, draw2
[EVALUATION RESULT]:(first)  win4, lose5, draw1
[EVALUATION RESULT]:(second) win5, lose4, draw1
------ Finished Self-Play Iteration 18 in 43.984s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (1330 examples) in 10.983s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win10, lose10, draw0
[EVALUATION RESULT]:(first)  win3, lose7, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 19 in 44.768s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (1710 examples) in 9.471s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose6, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win5, lose5, draw0
------ Finished Self-Play Iteration 20 in 42.074s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (2760 examples) in 10.914s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 21 in 40.849s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (660 examples) in 1.200s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose2, draw1
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 22 in 29.320s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (610 examples) in 2.143s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose5, draw1
[EVALUATION RESULT]:(first)  win6, lose3, draw1
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 23 in 32.664s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (1860 examples) in 10.344s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win11, lose8, draw1
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win4, lose5, draw1
------ Finished Self-Play Iteration 24 in 42.705s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (570 examples) in 1.417s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win12, lose7, draw1
[EVALUATION RESULT]:(first)  win6, lose4, draw0
[EVALUATION RESULT]:(second) win6, lose3, draw1
------ Finished Self-Play Iteration 25 in 33.851s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (1720 examples) in 9.184s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win12, lose7, draw1
[EVALUATION RESULT]:(first)  win5, lose5, draw0
[EVALUATION RESULT]:(second) win7, lose2, draw1
------ Finished Self-Play Iteration 26 in 38.927s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (1560 examples) in 13.746s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose4, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 27 in 43.915s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (540 examples) in 0.741s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win13, lose6, draw1
[EVALUATION RESULT]:(first)  win6, lose3, draw1
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 28 in 33.674s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (2650 examples) in 12.355s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 29 in 44.841s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (2720 examples) in 12.101s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose2, draw1
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win7, lose2, draw1
------ Finished Self-Play Iteration 30 in 44.177s ------

[round_robin] All done.
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (12580 examples) in 26.006s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 12580
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 1 in 65.086s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (13520 examples) in 28.978s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 26100
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 67.430s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (12420 examples) in 31.910s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 38520
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 68.036s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (12350 examples) in 33.773s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 50870
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 4 in 79.393s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (12050 examples) in 27.700s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 62920
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 66.891s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (12840 examples) in 33.621s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 75760
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 94.153s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (12530 examples) in 48.518s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 88.925s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (10870 examples) in 26.202s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 63.342s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (11250 examples) in 26.837s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 71.347s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (12890 examples) in 28.759s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 10 in 77.927s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (12600 examples) in 33.568s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 70.061s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (10370 examples) in 22.011s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 12 in 75.802s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (10970 examples) in 28.917s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 13 in 67.544s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (12000 examples) in 26.524s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 14 in 69.622s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (10080 examples) in 23.025s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 15 in 63.029s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (11830 examples) in 30.968s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 16 in 68.732s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (12130 examples) in 27.327s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 67.448s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (11560 examples) in 26.021s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 18 in 71.596s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (11740 examples) in 28.576s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 19 in 73.616s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (11800 examples) in 28.037s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 20 in 64.177s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (10770 examples) in 24.817s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 21 in 64.420s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (11010 examples) in 26.737s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 22 in 62.201s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (10970 examples) in 25.842s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 23 in 67.529s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (11900 examples) in 28.128s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 24 in 66.077s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (11310 examples) in 28.338s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 25 in 67.928s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (11980 examples) in 28.607s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 26 in 67.304s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (10770 examples) in 27.353s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 27 in 76.513s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (11160 examples) in 27.445s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 28 in 64.744s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (12560 examples) in 27.502s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 29 in 73.851s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (10690 examples) in 24.953s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 30 in 67.951s ------

[round_robin] All done.
------ Start Self-Play Iteration 1 ------
------ Start Self-Play Iteration 1 ------
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (11770 examples) in 1147.384s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 11770
------ Start Self-Play Iteration 1 ------
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (11770 examples) in 1088.451s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 11770
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 1 in 3644.509s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (12790 examples) in 1102.740s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 24560
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 2 in 3706.513s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (11420 examples) in 1028.007s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 35980
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (9100 examples) in 346.736s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 9100
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 1 in 1041.791s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (11620 examples) in 388.388s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 20720
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 2 in 873.872s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (12020 examples) in 335.516s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 32740
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 808.401s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (9950 examples) in 307.778s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 42690
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 778.728s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (10860 examples) in 322.353s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 53550
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 5 in 1113.582s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (11920 examples) in 440.976s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 65470
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 6 in 1141.712s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (11550 examples) in 312.265s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 77020
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 807.473s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (12540 examples) in 316.381s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 859.236s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (11310 examples) in 303.047s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 868.115s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (12050 examples) in 297.702s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 10 in 907.180s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (13500 examples) in 294.615s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 786.995s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (11900 examples) in 265.072s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 12 in 799.468s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (12470 examples) in 280.324s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 13 in 755.572s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (11640 examples) in 272.646s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 14 in 920.296s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (11600 examples) in 294.484s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 15 in 774.961s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (12500 examples) in 329.070s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 16 in 795.703s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (10620 examples) in 245.321s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 740.823s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (12190 examples) in 290.598s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 18 in 985.440s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (11800 examples) in 232.680s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 19 in 707.214s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (11310 examples) in 232.418s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 20 in 927.198s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (11650 examples) in 338.000s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 21 in 798.830s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (10160 examples) in 273.960s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 22 in 775.241s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (10700 examples) in 216.629s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 23 in 704.321s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (11430 examples) in 261.013s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 24 in 858.259s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (10470 examples) in 271.941s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 25 in 977.638s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (11010 examples) in 251.103s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 26 in 868.860s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (10500 examples) in 321.117s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 27 in 855.223s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (9650 examples) in 267.550s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 28 in 755.946s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (10080 examples) in 260.045s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 29 in 701.958s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (11520 examples) in 315.873s, Win: 0, Draw: 0, Lose: 0
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 30 in 981.011s ------

[round_robin] All done.
